{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJ79ebC00aWD"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "def extract_text_from_md(md_path):\n",
        "    \"\"\"Extract text from a given Markdown (.md) file.\"\"\"\n",
        "    with open(md_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def split_into_chunks(text, min_length=500, max_length=1000):\n",
        "    \"\"\"Chunk text while preserving section numbers.\"\"\"\n",
        "    sections = re.split(r'(\\n\\d+\\.\\s+)', text)  # Split while keeping section numbers\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for i in range(1, len(sections), 2):  # Iterate over section numbers and text\n",
        "        section_number = sections[i].strip() if i < len(sections) else \"\"\n",
        "        section_text = sections[i+1].strip() if i+1 < len(sections) else \"\"\n",
        "\n",
        "        if len(current_chunk) + len(section_text) < max_length:\n",
        "            current_chunk += f\"{section_number} {section_text}\\n\"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = f\"{section_number} {section_text}\"\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def chunk_legal_document(text):\n",
        "    # Regular expression to match section headers\n",
        "    section_pattern = re.compile(r'## Section \\d+:|# Offences .+')\n",
        "\n",
        "    # Split the text into chunks based on section headers\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    lines = text.split('\\n')\n",
        "    for line in lines:\n",
        "        if section_pattern.match(line):\n",
        "            if current_chunk:\n",
        "                chunks.append('\\n'.join(current_chunk))\n",
        "                current_chunk = []\n",
        "        current_chunk.append(line)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append('\\n'.join(current_chunk))\n",
        "\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjaRO_bt1o-i"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "with open(\"../data/bns_instructions.md\", 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "chunks = chunk_legal_document(text)\n",
        "\n",
        "# Print the first few chunks to verify\n",
        "for i, chunk in enumerate(chunks[:5]):\n",
        "    print(f\"Chunk {i+1}:\\n{chunk}\\n{'-'*40}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0DgSu-g1qoX"
      },
      "outputs": [],
      "source": [
        "data = {\"BNS\": chunks}\n",
        "\n",
        "with open(\"legal_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, indent=4)\n",
        "\n",
        "print(f\"Chunking completed!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
